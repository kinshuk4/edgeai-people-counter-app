# Project Introduction

In this project, you will utilize the Intel® Distribution of the OpenVINO™ Toolkit to build a People Counter app, including performing inference on an input video, extracting and analyzing the output data, then sending that data to a server. The model will be deployed on the edge, such that only data on 1) the number of people in the frame, 2) time those people spent in frame, and 3) the total number of people counted are sent to a MQTT server; inference will be done on the local machine.

You will also create a write-up comparing the performance of the model before and after use of the OpenVINO™ Toolkit, as well as examine potential use cases for your deployed people counter app.

In completing the project, you’ll get hands-on experience optimizing models for inference with the OpenVINO™ Toolkit, as well as building skills handling and extracting useful information from the deployed models.



## Provided Files

You will be provided with complete files implementing:

1. A MQTT server - receives JSON from your primary code subsequent to inference concerning people counted, duration they spent in frame, and total people counted. This will feed to the UI server.
2. A UI server - displays a video feed as well as statistics received from the MQTT server.
3. A FFmpeg server - receives output image frames including any detected outputs inferred by the model. This is then fed to the UI server.

While the above files are provided complete so that no additional front-end or web services work is required from you, feel free to adjust these as you see fit. For instance, how can you save on network bandwidth by adding a toggle to turn off the sending and receiving of the image frame, only focusing on the statistics from the lightweight MQTT server?

Additionally, you will be provided with a video file to test your implementation, although your code should allow for other inputs, such as a single image or webcam stream.

You will also be provided with starter code for your implementation, split into two files:

1. `inference.py` - Here, you will load the Intermediate Representation of the model, and work with the Inference Engine to actually perform inference on an input.

2. `main.py` - Here, you will:
   - Connect to the MQTT server
   - Handle the input stream
   - Use your work from `inference.py` to perform inference
   - Extract the model output, and draw any necessary information on the frame (bounding boxes, semantic masks, etc.)
   - Perform analysis on the output to determine the number of people in frame, time spent in frame, and the total number of people counted
   - Send statistics to the MQTT server
   - Send processed frame to FFmpeg

More detail on the above files will be provided in the upcoming project instructions.

https://classroom.udacity.com/nanodegrees/nd131/parts/d334a449-003a-48fb-8d8a-079cba821e76/modules/efc7c11f-29c0-43d5-a7a9-1a7c25fe0c4b/lessons/ff92f8be-2afd-4077-90f9-f6ddc1624e9f/concepts/79d2efcc-cfc5-4b64-8333-b95c3e84577a

